<?xml version="1.0" encoding="UTF-8"?><xml><records><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Baeza-Yates, Ricardo</author><author>Ribeiro-Neto, Berthier</author></authors></contributors><titles><title>Modern Information Retrieval: The Concepts and Technology behind Search</title><secondary-title>Information Retrieval</secondary-title></titles><periodical><full-title>Information Retrieval</full-title></periodical><pages>944</pages><volume>82</volume><keywords/><dates><year>2011</year></dates><isbn>0321416910</isbn><urls><pdf-urls><url>internal-pdf://Baeza-Yates, Ribeiro-Neto - 2011 - Modern Information Retrieval The Concepts and Technology behind Search(2).pdf</url><url>internal-pdf://Baeza-Yates, Ribeiro-Neto - 2011 - Modern Information Retrieval The Concepts and Technology behind Search.pdf</url></pdf-urls><web-urls><url>http://www.amazon.com/Modern-Information-Retrieval-Concepts-Technology/dp/0321416910</url></web-urls></urls><abstract>Comprehensive guide to information retrieval by leading international experts including web retrievel, web crawling, open source search engines and user interfaces.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Bird, Steven</author><author>Klein, Ewan</author><author>Loper, Edward</author></authors></contributors><titles><title>Natural Language Processing with Python</title><secondary-title>Text</secondary-title></titles><periodical><full-title>Text</full-title></periodical><pages>479</pages><volume>43</volume><keywords/><dates><year>2009</year></dates><isbn>9780596516499</isbn><accession-num>12043876</accession-num><urls><pdf-urls><url>internal-pdf://Bird, Klein, Loper - 2009 - Natural Language Processing with Python.pdf</url></pdf-urls><web-urls><url>http://www.nltk.org/book/</url></web-urls></urls><abstract>This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify &quot;named entities&quot; Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages - or if you're simply curious to have a programmer's perspective on how human language works - you'll find Natural Language Processing with Python both fascinating and immensely useful.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Thesis">2</ref-type><contributors><authors><author>Bobrow, Daniel G.</author></authors></contributors><titles><title>Natural Language Input for a Computer Problem Solving System</title></titles><periodical/><keywords/><dates><year>1964</year></dates><publisher>MIT</publisher><electronic-resource-num>1721.1/5922</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Bobrow - 1964 - Natural Language Input for a Computer Problem Solving System.pdf</url></pdf-urls></urls><label>Bobrow1964</label><abstract>This paper describes a computer program which accepts and «understands» a comfortable, but restricted set of one natural language, English. Certain difficulties are inherent in this problem of making a machine «understand» English. Within the limited framework of the subject matter understood by the program, many of these problems are solved or circumvented. I shall describe these problems and my solutions, and point out those solutions which I feel have general applicability. I will also indicate which must be replaced by more general methods to be really useful, and give my ideas about what general solutions to these particular problems might entail.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Bocklage-Ryannel, Jürgen</author><author>Thelin, Johan</author></authors></contributors><titles><title>QmlBook</title></titles><periodical/><keywords/><urls><web-urls><url>https://qmlbook.github.io/index.html</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Boehm, Barry W</author></authors></contributors><titles><title>A spiral model of software development and enhancement</title><secondary-title>Computer</secondary-title></titles><periodical><full-title>Computer</full-title></periodical><pages>61-72</pages><volume>21</volume><issue>5</issue><keywords/><dates><year>1988</year></dates><publisher>IEEE</publisher><urls><pdf-urls><url>internal-pdf://Boehm - 1988 - A spiral model of software development and enhancement.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Bouckaert, Remco R.</author><author>Frank, Eibe</author><author>Kirkby, Richard</author><author>Reutemann, Peter</author><author>Seewald, Alex</author><author>Scuse, David</author></authors></contributors><titles><title>WEKA Manual for Version 3-7-2</title></titles><periodical/><keywords/><dates><year>2002</year></dates><urls><pdf-urls><url>internal-pdf://Bouckaert et al. - 2002 - WEKA Manual for Version 3-7-2.pdf</url></pdf-urls><web-urls><url>http://netcologne.dl.sourceforge.net/project/weka/documentation/3.7.x/WekaManual-3-7-12.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Bressert, E</author></authors></contributors><titles><title>SciPy and NumPy</title></titles><periodical/><keywords/><dates><year>2012</year></dates><publisher>O'Reilly</publisher><isbn>9781449305468</isbn><urls><pdf-urls><url>internal-pdf://Bressert - 2012 - SciPy and NumPy.pdf</url></pdf-urls><web-urls><url>https://books.google.es/books?id=-N9ZBsjW3IIC</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Chomsky, Noam</author></authors></contributors><titles><title>Aspects of the Theory of Syntax</title><secondary-title>Aspects of the Theory of Syntax</secondary-title></titles><periodical><full-title>Aspects of the Theory of Syntax</full-title></periodical><pages>251</pages><volume>119</volume><issue>no 11</issue><keywords/><dates><year>1965</year></dates><isbn>0262530074</isbn><accession-num>3586770</accession-num><electronic-resource-num>10.1016/0732-118X(86)90008-5</electronic-resource-num><urls/><abstract>Beginning in the mid-fifties and emanating largely form MIT, and approach was developed to linguistic theory and to the study of the structure of particular languages that diverges in many respects from modern linguistics. Although this approach is connected to the traditional study of languages, it differs enough in its specific conclusions about the structure and in its specific conclusions about the structure of language to warrant a name, &quot;generative grammar.&quot;Various deficiencies have been discovered in the first attempts to formulate a theory of transformational generative grammar and in the descriptive analysis of particular languages that motivated these formulations. At the same time, it has become apparent that these formulations can be extended and deepened.The major purpose of this book is to review these developments and to propose a reformulation of the theory of transformational generative grammar that takes them into account. The emphasis in this study is syntax; semantic and phonological aspects of the language structure are discussed only insofar as they bear on syntactic theory.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>de Nebrija, Elio Antonio</author></authors></contributors><titles><title>Gramática castellana</title></titles><periodical/><keywords/><dates><year>1492</year></dates><urls><pdf-urls><url>internal-pdf://de Nebrija - 1492 - Gramática castellana.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>De Zubira Samper, Miguel</author></authors></contributors><titles><title>Teoría de las seis lecturas</title></titles><periodical/><keywords/><dates><year>2002</year></dates><publisher>Fondo de publicaciones Merani</publisher><isbn>9789589405062</isbn><urls><web-urls><url>https://books.google.es/books?id=PFfmoAEACAAJ</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Desconocido</author></authors></contributors><titles><title>Text Mining Online | Text Analysis Online | Text Processing Online</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><web-urls><url>http://textminingonline.com</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Díaz Santos, Rosa</author></authors></contributors><titles><title>Lenguaje natural, lenguaje artificial</title></titles><periodical/><keywords/><urls><web-urls><url>http://ficus.pntic.mec.es/rdis0006/lecciones/logica_proposicional/lecciones/lenguaje natural.htm</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Domingos, Pedro</author></authors></contributors><titles><title>A few useful things to know about machine learning</title><secondary-title>Communications of the ACM</secondary-title></titles><periodical><full-title>Communications of the ACM</full-title></periodical><pages>78</pages><volume>55</volume><issue>10</issue><keywords/><dates><year>2012</year></dates><isbn>0001-0782</isbn><electronic-resource-num>10.1145/2347736.2347755</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Domingos - 2012 - A few useful things to know about machine learning.pdf</url><url>internal-pdf://Domingos - 2012 - A few useful things to know about machine learning(2).pdf</url></pdf-urls></urls><abstract>MACHINE LEARNING SYSTEMS automatically learn programs from data. This is often a very attractive alternative to manually constructing them, and in the last decade the use of machine learning has spread rapidly throughout computer science and beyond. Machine learning is used in Web search, spam filters, recommender systems, ad placement, credit scoring, fraud detection, stock trading, drug design, and many other applications. A recent report from the McKinsey Global Institute asserts that machine learning (a.k.a. data mining or predictive analytics) will be the driver of the next big wave of innovation. Several fine textbooks are available to interested practitioners and researchers (for example, Mitchell and Witten et al.). However, much of the ``folk knowledge'' that is needed to successfully develop machine learning applications is not readily available in them. As a result, many machine learning projects take much longer than necessary or wind up producing less-than-ideal results. Yet much of this folk knowledge is fairly easy to communicate. This is the purpose of this article.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Edmondson, Jerold A.</author></authors></contributors><titles><title>Formal Semantics of Natural Language (book review)</title><secondary-title>Lingua</secondary-title></titles><periodical><full-title>Lingua</full-title></periodical><pages>355-374</pages><volume>45</volume><issue>3-4</issue><keywords/><dates><year>1978</year></dates><electronic-resource-num>10.1016/0024-3841(78)90031-1</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Edmondson - 1978 - Formal Semantics of Natural Language (book review).pdf</url></pdf-urls><web-urls><url>http://www.sciencedirect.com/science/article/pii/0024384178900311</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Gabilondo, Michael</author></authors></contributors><titles><title>How to perform some common NLP tasks using NLTK</title></titles><periodical/><keywords/><urls><pdf-urls><url>internal-pdf://Gabilondo - Unknown - How to perform some common NLP tasks using NLTK.pdf</url></pdf-urls><web-urls><url>http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf</url></web-urls></urls><label>Gabilondo2011</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Gabrilovich, Evgeniy</author><author>Markovitch, Shaul</author></authors></contributors><titles><title>Feature Generation for Text Categorization Using World Knowledge</title><secondary-title>Proceedings of the 19th International Joint Conference for Artificial Intelligence</secondary-title></titles><periodical><full-title>Proceedings of the 19th International Joint Conference for Artificial Intelligence</full-title></periodical><pages>1048-1053</pages><keywords><keyword>Common-Sense Knowledge</keyword><keyword>Feature Generation</keyword><keyword>Informat</keyword></keywords><dates><year>2005</year></dates><urls><pdf-urls><url>internal-pdf://Gabrilovich, Markovitch - 2005 - Feature Generation for Text Categorization Using World Knowledge.pdf</url></pdf-urls><web-urls><url>http://www.cs.technion.ac.il/~shaulm/papers/pdf/Gabrilovich-Markovitch-ijcai2005.pdf</url></web-urls></urls><label>Gabrilovich2005</label><abstract>We enhance machine learning algorithms for text categorization with generated features based on domain-specific and common-sense knowledge. This knowledge is represented using publicly available ontologies that contain hundreds of thousands of concepts, such as the Open Directory; these ontologies are further enriched by several orders of magnitude through controlled Web crawling. Prior to text categorization, a feature generator analyzes the documents and maps them onto appropriate ontology concepts, which in turn induce a set of generated features that augment the standard bag of words. Feature generation is accomplished through contextual analysis of document text, implicitly performing word sense disambiguation. Coupled with the ability to generalize concepts using the ontology, this approach addresses the two main problems of natural language processing---synonymy and polysemy. Categorizing documents with the aid of knowledge-based features leverages information that cannot be deduced from the documents alone. Experimental results confirm improved performance, breaking through the plateau previously reached in the field.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Gallego, Angel J.</author></authors></contributors><titles><title>La jerarquía de Chomsky y la facultad del lenguaje: consecuencias para la variación y la evolución</title><secondary-title>Teorema: Revista internacional de filosofía</secondary-title></titles><periodical><full-title>Teorema: Revista internacional de filosofía</full-title></periodical><pages>47-60</pages><volume>27</volume><issue>2</issue><keywords><keyword>Filosofía. Etica</keyword><keyword>Grupo A</keyword><keyword>Grupo B</keyword><keyword>Humanidades</keyword></keywords><dates><year>2008</year></dates><publisher>KRK Ediciones</publisher><language>spa</language><urls><pdf-urls><url>internal-pdf://Gallego - 2008 - La jerarquía de Chomsky y la facultad del lenguaje consecuencias para la variación y la evolución.pdf</url></pdf-urls><web-urls><url>http://dialnet.unirioja.es/servlet/articulo?codigo=2580734</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Thesis">2</ref-type><contributors><authors><author>Gerber, Matthew</author></authors></contributors><titles><title>Semantic Role Labeling of Implicit Arguments for Nominal Predicates</title></titles><periodical/><keywords/><dates><year>2011</year></dates><urls><pdf-urls><url>internal-pdf://Gerber - 2011 - Semantic Role Labeling of Implicit Arguments for Nominal Predicates.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Google</author></authors></contributors><titles><title>Creating a Sentiment Analysis Model - Prediction API — Google Cloud Platform</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><web-urls><url>https://cloud.google.com/prediction/docs/sentiment_analysis</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Handke, Jürgen</author></authors></contributors><titles><title>Natural Language Processing : Structure of the Lexicon : Human versus Machine</title></titles><periodical/><keywords><keyword>Computational linguistics.</keyword><keyword>Lexicology -- Data processing.</keyword></keywords><dates><year>2012</year></dates><pub-location>Tubingen, DEU</pub-location><publisher>Walter de Gruyter</publisher><isbn>9783110907865</isbn><urls><pdf-urls><url>internal-pdf://Handke - 2012 - Natural Language Processing Structure of the Lexicon Human versus Machine.pdf</url></pdf-urls><web-urls><url>http://site.ebrary.com/lib/bibucascb/docDetail.action?docID=10755060</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Thesis">2</ref-type><contributors><authors><author>Handler, Abram</author></authors></contributors><titles><title>An empirical study of semantic similarity in WordNet and Word2Vec</title><secondary-title>University of New Orleans Theses and Dissertations</secondary-title></titles><periodical><full-title>University of New Orleans Theses and Dissertations</full-title></periodical><keywords/><dates><year>2014</year></dates><urls><pdf-urls><url>internal-pdf://Handler - 2014 - An empirical study of semantic similarity in WordNet and Word2Vec.pdf</url></pdf-urls><web-urls><url>http://scholarworks.uno.edu/td/1922</url></web-urls></urls><abstract>This thesis performs an empirical analysis of Word2Vec by comparing its output to WordNet, a well-known, human-curated lexical database. It finds that Word2Vec tends to uncover more of certain types of semantic relations than others -- with Word2Vec returning more hypernyms, synonomyns and hyponyms than hyponyms or holonyms. It also shows the probability that neighbors separated by a given cosine distance in Word2Vec are semantically related in WordNet. This result both adds to our understanding of the still-unknown Word2Vec and helps to benchmark new semantic tools built from word vectors.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Hearst, Marti A.</author></authors></contributors><titles><title>Search User Interfaces</title><secondary-title>Search User Interfaces</secondary-title></titles><periodical><full-title>Search User Interfaces</full-title></periodical><pages>404</pages><volume>54</volume><issue>Ch 1</issue><keywords><keyword>among others</keyword><keyword>at</keyword><keyword>face</keyword><keyword>inter-</keyword><keyword>is promoted by researchers</keyword><keyword>microsoft</keyword><keyword>natural inter-</keyword><keyword>not sur-</keyword><keyword>people are drawn to</keyword><keyword>prisingly</keyword><keyword>the term</keyword></keywords><dates><year>2009</year></dates><publisher>Search User Interfaces</publisher><isbn>0521113792</isbn><accession-num>15784401</accession-num><electronic-resource-num>10.1145/2018396.2018414</electronic-resource-num><notes>http://people.ischool.berkeley.edu/~hearst/talks/upitt.pdf</notes><research-notes>http://people.ischool.berkeley.edu/~hearst/talks/upitt.pdf</research-notes><urls><web-urls><url>http://searchuserinterfaces.com/book/</url></web-urls></urls><abstract>This book focuses on the human users of search engines and the tool they use to interact with them: the search user interface. The truly worldwide reach of the Web has brought with it a new realization among computer scientists and laypeople of the enormous importance of usability and user interface design. In the last ten years, much has become understood about what works in search interfaces from a usability perspective, and what does not. Researchers and practitioners have developed a wide range of innovative interface ideas, but only the most broadly acceptable make their way into major web search engines. This book summarizes these developments, presenting the state of the art of search interface design, both in academic research and in deployment in commercial systems. Many books describe the algorithms behind search engines and information retrieval systems, but the unique focus of this book is specifically on the user interface. It will be welcomed by industry professionals who design systems that use search interfaces as well as graduate students and academic researchers who investigate information systems.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Hearst, Marti A.</author></authors></contributors><titles><title>Automatic Acquisition of Hyponyms from Large Text Corpora</title><secondary-title>Proceedings of the 14th International Conference on Computational Linguistics</secondary-title></titles><periodical><full-title>Proceedings of the 14th International Conference on Computational Linguistics</full-title></periodical><pages>539-545</pages><keywords/><dates><year>1992</year></dates><electronic-resource-num>10.1.1.36.701</electronic-resource-num><notes>http://people.ischool.berkeley.edu/~hearst/</notes><research-notes>http://people.ischool.berkeley.edu/~hearst/</research-notes><urls><pdf-urls><url>internal-pdf://Hearst - 1992 - Automatic Acquisition of Hyponyms from Large Text Corpora.pdf</url></pdf-urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.36.701</url></web-urls></urls><abstract>We describe a method for the automatic acquisition of the hyponymy lexical relation from unrestricted text. Two goals motivate the approach: (i) avoidance of the need for pre-encoded knowledge and (ii) applicability across a wide range of text. We identify a set of lexicosyntactic patterns that are easily recognizable, that occur frequently and across text genre boundaries, and that indisputably indicate the lexical relation of interest. We describe a method for discovering these patterns and suggest that other lexical relations will also be acquirable in this way. A subset of the acquisition algorithm is implemented and the results are used to augment and critique the structure of a large hand-built thesaurus. Extensions and applications to areas such as information retrieval are suggested. 1 Introduction Currently there is much interest in the automatic acquisition of lexical syntax and semantics, with the goal of building up large lexicons for natural language processing. Projects ...</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Hilbert, Martin</author><author>López, Priscila</author></authors></contributors><titles><title>How to measure the world's technological capacity to communicate, store, and compute information, part I: Results and scope</title><secondary-title>International Journal of Communication</secondary-title></titles><periodical><full-title>International Journal of Communication</full-title></periodical><pages>956-979</pages><volume>6</volume><issue>1</issue><keywords/><dates><year>2012</year></dates><isbn>1932-8036</isbn><urls><pdf-urls><url>internal-pdf://Hilbert, López - 2012 - How to measure the world's technological capacity to communicate, store, and compute information, part I Result.pdf</url></pdf-urls></urls><abstract>This is Part I of a two-part article that reviews methodological and statistical challenges involved in the estimation of humanity’s technological capacity to communicate, store, and compute information. It is written from the perspective of the results of our recent inventory of 60 technological categories between 1986 and 2007 (measured in bits and MIPS [million-instructions-per-second]). In Part I, we summarize the results of our inventory, and explore a series of basic choices that must be made in the course of measuring information and communication capacities. The most basic underlying assumptions behind our estimates include—among others—decisions about what is counted as (1) communication, (2) storage, and (3) computation; if technological capacities or consumption of information is measured; and if unique information is distinguished from duplicate information. We compare our methodological choices with different approaches taken in similar studies. The article shows how the particular question on the researcher’s mind, as well as the availability of source data has and will influence most of the methodological choices in different exercises.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hilbert, Martin</author><author>López, Priscila</author></authors></contributors><titles><title>The world's technological capacity to store, communicate, and compute information</title><secondary-title>Science (New York, N.Y.)</secondary-title></titles><periodical><full-title>Science (New York, N.Y.)</full-title></periodical><pages>60-65</pages><volume>332</volume><issue>6025</issue><keywords/><dates><year>2011</year></dates><isbn>1095-9203</isbn><accession-num>21310967</accession-num><electronic-resource-num>10.1126/science.1200970</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Hilbert, López - 2011 - The world's technological capacity to store, communicate, and compute information.pdf</url></pdf-urls></urls><abstract>We estimated the world's technological capacity to store, communicate, and compute information, tracking 60 analog and digital technologies during the period from 1986 to 2007. In 2007, humankind was able to store 2.9 × 10(20) optimally compressed bytes, communicate almost 2 × 10(21) bytes, and carry out 6.4 × 10(18) instructions per second on general-purpose computers. General-purpose computing capacity grew at an annual rate of 58%. The world's capacity for bidirectional telecommunication grew at 28% per year, closely followed by the increase in globally stored information (23%). Humankind's capacity for unidirectional information diffusion through broadcasting channels has experienced comparatively modest annual growth (6%). Telecommunication has been dominated by digital technologies since 1990 (99.9% in digital format in 2007), and the majority of our technological memory has been in digital format since the early 2000s (94% digital in 2007).</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Huang, S</author></authors></contributors><titles><title>Qt 5 Blueprints</title></titles><periodical/><keywords/><dates><year>2015</year></dates><publisher>Packt Publishing</publisher><isbn>9781784390761</isbn><urls><web-urls><url>https://books.google.es/books?id=oNe6BwAAQBAJ</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Hurtado Rodríguez, Nuria</author><author>González Romano, J Mariano</author><author>Torres Valderrama, Jesús</author></authors></contributors><titles><title>Revisión de lenguajes declarativos para la descripción de interfaces de usuario independientes del dispositivo</title><secondary-title>Interface</secondary-title></titles><periodical><full-title>Interface</full-title></periodical><pages>223-226</pages><volume>3-7 mayo</volume><keywords><keyword>escuela superior de ingeniería</keyword><keyword>informáticos</keyword><keyword>universidad de cádiz</keyword></keywords><dates><year>2004</year></dates><urls><pdf-urls><url>internal-pdf://Hurtado Rodríguez, González Romano, Torres Valderrama - 2004 - Revisión de lenguajes declarativos para la descripción de interfaces.pdf</url></pdf-urls><web-urls><url>http://www.aipo.es/aipo/articulos/3/32.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Idris, I</author></authors></contributors><titles><title>NumPy Cookbook - Second Edition</title></titles><periodical/><keywords/><dates><year>2015</year></dates><publisher>Packt Publishing</publisher><isbn>9781784399825</isbn><urls><pdf-urls><url>internal-pdf://Idris - 2015 - NumPy Cookbook - Second Edition.pdf</url></pdf-urls><web-urls><url>https://books.google.es/books?id=zWHCCAAAQBAJ</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>IEEE Software Engineering Standars Comitee</author></authors></contributors><titles><title>IEEE Recommended Practice for Software Requirements Specifications 830-1998</title><secondary-title>Electronics</secondary-title></titles><periodical><full-title>Electronics</full-title></periodical><keywords><keyword>contract</keyword><keyword>customer</keyword><keyword>prototyping</keyword><keyword>software requirements specification</keyword><keyword>supplier</keyword><keyword>system requirements specifications</keyword></keywords><dates><year>1998</year></dates><isbn>0738103322</isbn><urls><pdf-urls><url>internal-pdf://IEEE Software Engineering Standars Comitee - 1998 - IEEE Recommended Practice for Software Requirements Specifications 830-1998.pdf</url></pdf-urls></urls><abstract>The content and qualities of a good software requirements specification (SRS) are described and several sample SRS outlines are presented. This recommended practice is aimed at specifying requirements of software to be developed but also can be applied to assist in the selec- tion of in-house and commercial software products. Guidelines for compliance with IEEE/EIA 12207.1-1997 are also provided.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Jansen, Bernard J</author><author>Zhang, Mimi</author><author>Sobel, Kate</author><author>Chowdury, Abdur</author></authors></contributors><titles><title>Twitter power: Tweets as electronic word of mouth</title><secondary-title>Journal of the American society for information science and technology</secondary-title></titles><periodical><full-title>Journal of the American society for information science and technology</full-title></periodical><pages>2169-2188</pages><volume>60</volume><issue>11</issue><keywords/><dates><year>2009</year></dates><publisher>Wiley Online Library</publisher><urls><pdf-urls><url>internal-pdf://Jansen et al. - 2009 - Twitter power Tweets as electronic word of mouth.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Jiménez Millán, José Antonio</author></authors></contributors><titles><title>Compiladores y procesadores de lenguajes</title></titles><periodical/><pages>273</pages><keywords/><dates><year>2004</year></dates><publisher>Servicio de publicaciones de la Universidad de Cádiz</publisher><isbn>978-84-7786-383-0</isbn><urls/></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Jurafsky, Dan</author><author>Manning, Christopher D.</author></authors></contributors><titles><title>Natural Language Processing - Coursera class</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><web-urls><url>https://class.coursera.org/nlp/lecture/25</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Karray, Fakhreddine</author><author>Alemzadeh, Milad</author><author>Saleh, Jamil Abou</author><author>Arab, Mo Nours</author></authors></contributors><titles><title>Human-Computer Interaction: Overview on State of the Art</title><secondary-title>International Journal on Smart Sensing and Intelligent Systems</secondary-title></titles><periodical><full-title>International Journal on Smart Sensing and Intelligent Systems</full-title></periodical><volume>1</volume><issue>1</issue><keywords/><dates><year>2008</year></dates><urls><pdf-urls><url>internal-pdf://Karray et al. - 2008 - Human-Computer Interaction Overview on State of the Art.pdf</url></pdf-urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/summary?doi=10.1.1.331.6558</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Keenan, Eduard L.</author></authors></contributors><titles><title>Formal Semantics of Natural Language</title></titles><periodical/><pages>492</pages><keywords/><dates><year>2009</year></dates><publisher>Cambridge University Press</publisher><isbn>9780521111119</isbn><urls><web-urls><url>https://books.google.es/books?id=3o5bPwAACAAJ</url></web-urls></urls><abstract>A volume of studies in natural language semantics which brings together work by philosophers, logicians and linguists. The main topics treated are: quantification and reference in natural language; the relations between formal logic, programming languages and natural language; pragmatics and discourse meaning; surface syntax and logical meaning. The volume derives from a colloquium organised in 1973 by the Kings College Research Centre, Cambridge and the papers have been edited for publication by Professor Keenan. It is hoped that the collection will make available some of the best work in this fast-moving field and will stimulate further progress by juxtaposing the different approaches and interests represented here.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Le, Quoc V.</author><author>Mikolov, Tomas</author></authors></contributors><titles><title>Distributed Representations of Sentences and Documents</title><secondary-title>Proceedings of the 31st International Conference on Machine Learning</secondary-title></titles><periodical><full-title>Proceedings of the 31st International Conference on Machine Learning</full-title></periodical><pages>1188-1196</pages><volume>32</volume><keywords/><dates><year>2014</year></dates><isbn>9781634393973</isbn><urls><pdf-urls><url>internal-pdf://Le, Mikolov - 2014 - Distributed Representations of Sentences and Documents.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1405.4053</url></web-urls></urls><abstract>Many machine learning algorithms require the input to be represented as a fixed-length feature vector. When it comes to texts, one of the most common fixed-length features is bag-of-words. Despite their popularity, bag-of-words features have two major weaknesses: they lose the ordering of the words and they also ignore semantics of the words. For example, &quot;powerful,&quot; &quot;strong&quot; and &quot;Paris&quot; are equally distant. In this paper, we propose Paragraph Vector, an unsupervised algorithm that learns fixed-length feature representations from variable-length pieces of texts, such as sentences, paragraphs, and documents. Our algorithm represents each document by a dense vector which is trained to predict words in the document. Its construction gives our algorithm the potential to overcome the weaknesses of bag-of-words models. Empirical results show that Paragraph Vectors outperform bag-of-words models as well as other techniques for text representations. Finally, we achieve new state-of-the-art results on several text classification and sentiment analysis tasks.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Leiva-Aguilera, J</author></authors></contributors><titles><title>Gestión de la reputación online</title></titles><periodical/><keywords/><dates><year>2012</year></dates><publisher>UOC</publisher><isbn>9788497889902</isbn><urls/></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Loganathan, Venkateshwaran</author></authors></contributors><titles><title>PySide GUI application development</title></titles><periodical/><pages>140</pages><keywords/><dates><year>2013</year></dates><publisher>Packt Publishing Ltd</publisher><isbn>9781849699594</isbn><urls><pdf-urls><url>internal-pdf://Loganathan - 2013 - PySide GUI application development.pdf</url></pdf-urls><web-urls><url>http://www.it-ebooks.info/book/3704/</url></web-urls></urls><abstract>Elegantly built GUI applications are always a massive hit among users. PySide is an open source software project that provides Python bindings for the Qt cross-platform UI framework. Combining the power of Qt and Python, PySide provides easy access to the Qt framework for Python developers and also acts as an excellent rapid application development platform available on all major operating systems. This book aims to help you develop GUI applications easily using PySide. Python is easy to learn and use and its programs are relatively shorter than those written in other programming languages like C++ or Java. This book will introduce you to user interface programming in Python, allowing you to develop real-time applications in a shorter amount of time.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Manning, Christopher D.</author><author>Raghavan, Prabhakar</author><author>Schütze, Hinrich</author></authors></contributors><titles><title>Introduction to Information Retrieval</title><secondary-title>Journal of the American Society for Information Science and Technology</secondary-title></titles><periodical><full-title>Journal of the American Society for Information Science and Technology</full-title></periodical><pages>496</pages><volume>1</volume><keywords/><dates><year>2008</year></dates><publisher>Cambridge University Press</publisher><isbn>0521865719</isbn><accession-num>12049181</accession-num><electronic-resource-num>10.1002/asi.21234</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Manning, Raghavan, Schütze - 2008 - Introduction to Information Retrieval.pdf</url></pdf-urls><web-urls><url>http://nlp.stanford.edu/IR-book/</url></web-urls></urls><abstract>Introduction to Information Retrieval is the first textbook with a coherent treatment of classical and web information retrieval, including web search and the related areas of text classification and text clustering. Written from a computer science perspective, it gives an up-to-date treatment of all aspects of the design and implementation of systems for gathering, indexing, and searching documents; methods for evaluating systems; and an introduction to the use of machine learning methods on text collections. Designed as the primary text for a graduate or advanced undergraduate course in information retrieval, the book will also interest researchers and professionals. A complete set of lecture slides and exercises that accompany the book are available on the web.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Manning, Christopher D.</author><author>Schütze, Hinrich</author></authors></contributors><titles><title>Foundations of Statistical Natural Language Processing</title><secondary-title>Reading</secondary-title></titles><periodical><full-title>Reading</full-title></periodical><pages>620</pages><keywords/><dates><year>1999</year></dates><publisher>MIT press</publisher><isbn>9780262133609</isbn><urls><pdf-urls><url>internal-pdf://Manning, Schütze - 1999 - Foundations of Statistical Natural Language Processing.pdf</url><url>internal-pdf://Manning, Schütze - 1999 - Foundations of Statistical Natural Language Processing(2).pdf</url></pdf-urls><web-urls><url>http://nlp.stanford.edu/fsnlp/</url></web-urls></urls><abstract>The Handbook of Natural Language Processing, Second Edition presents practical tools and techniques for implementing natural language processing in computer systems. Along with removing outdated material, this edition updates every chapter and expands the content to include emerging areas, such as sentiment analysis. New to the Second Edition Greater prominence of statistical approaches New applications section Broader multilingual scope to include Asian and European languages, along with English An actively maintained wiki that provides online resources, supplementary information, and up-to-date developments Divided into three sections, the book first surveys classical techniques, including both symbolic and empirical approaches. The second section focuses on statistical approaches in natural language processing. In the final section of the book, each chapter describes a particular class of application, from Chinese machine translation to information visualization to ontology construction to biomedical text mining. Fully updated with the latest developments in the field, this comprehensive, modern handbook emphasizes how to implement practical language processing tools in computational systems.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Generic">31</ref-type><contributors><authors><author>Martín Mateos, F. J.</author><author>Ruiz Reina, J. L.</author></authors></contributors><titles><title>Procesamiento del lenguaje natural</title></titles><periodical/><keywords/><dates><year>2013</year></dates><publisher>Dpto. Ciencias de la Computación e Inteligencia Artificial. Universidad de Sevilla</publisher><urls><pdf-urls><url>internal-pdf://Martín Mateos, Ruiz Reina - 2013 - Procesamiento del lenguaje natural.pdf</url></pdf-urls><web-urls><url>http://www.cs.us.es/cursos/ia2/temas/tema-06.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Mikolov, Tomas</author></authors></contributors><titles><title>word2vec - Tool for computing continuous distributed representations of words</title></titles><periodical/><keywords/><urls><web-urls><url>https://code.google.com/p/word2vec/</url></web-urls></urls><label>word2vec</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Mikolov, Tomas</author><author>Chen, Kai</author><author>Corrado, Greg</author><author>Dean, Jeffrey</author></authors></contributors><titles><title>Distributed Representations of Words and Phrases and their Compositionality</title><secondary-title>NIPS</secondary-title></titles><periodical><full-title>NIPS</full-title></periodical><pages>1-9</pages><volume>abs/1310.4</volume><keywords/><dates><year>2013</year></dates><urls><pdf-urls><url>internal-pdf://Mikolov et al. - 2013 - Distributed Representations of Words and Phrases and their Compositionality.pdf</url></pdf-urls><web-urls><url>http://arxiv.org/abs/1310.4546</url></web-urls></urls><abstract>The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large num- ber of precise syntactic and semantic word relationships. In this paper we present several extensions that improve both the quality of the vectors and the training speed. By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations. We also describe a simple alterna- tive to the hierarchical softmax called negative sampling. An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases. For example, the meanings of “Canada” and “Air” cannot be easily combined to obtain “Air Canada”. Motivated by this example,we present a simplemethod for finding phrases in text, and show that learning good vector representations for millions of phrases is possible.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Mikolov, Tomas</author><author>Corrado, Greg</author><author>Chen, Kai</author><author>Dean, Jeffrey</author></authors></contributors><titles><title>Efficient Estimation of Word Representations in Vector Space</title><secondary-title>Proceedings of the International Conference on Learning Representations (ICLR 2013)</secondary-title></titles><periodical><full-title>Proceedings of the International Conference on Learning Representations (ICLR 2013)</full-title></periodical><pages>1-12</pages><keywords/><dates><year>2013</year></dates><urls><pdf-urls><url>internal-pdf://Mikolov et al. - 2013 - Efficient Estimation of Word Representations in Vector Space.pdf</url></pdf-urls></urls><abstract>We propose two novel model architectures for computing continuous vector representations of words from very large data sets. The quality of these representations is measured in a word similarity task, and the results are compared to the previously best performing techniques based on different types of neural networks. We observe large improvements in accuracy at much lower computational cost, i.e. it takes less than a day to learn high quality word vectors from a 1.6 billion words data set. Furthermore, we show that these vectors provide state-of-the-art performance on our test set for measuring syntactic and semantic word similarities.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Mikolov, Tomas</author><author>Kombrink, Stefan</author><author>Burget, Lukas</author><author>Cernocky, Jan</author><author>Khudanpur, Sanjeev</author></authors></contributors><titles><title>Extensions of recurrent neural network language model</title><secondary-title>2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</secondary-title><short-title>Acoustics, Speech and Signal Processing (ICASSP)</short-title></titles><periodical><full-title>2011 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP)</full-title></periodical><pages>5528-5531</pages><keywords><keyword>Artificial neural networks</keyword><keyword>Backpropagation</keyword><keyword>Computational modeling</keyword><keyword>Probability distribution</keyword><keyword>Recurrent neural networks</keyword><keyword>Training</keyword><keyword>Vocabulary</keyword><keyword>backpropagation</keyword><keyword>competitive language modeling techniques</keyword><keyword>computational complexity</keyword><keyword>feedforward network</keyword><keyword>feedforward neural nets</keyword><keyword>language modeling</keyword><keyword>natural language processing</keyword><keyword>recurrent neural nets</keyword><keyword>recurrent neural network language model</keyword><keyword>recurrent neural networks</keyword><keyword>speech recognition</keyword></keywords><dates><year>2011</year></dates><publisher>IEEE</publisher><isbn>978-1-4577-0538-0</isbn><electronic-resource-num>10.1109/ICASSP.2011.5947611</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Mikolov et al. - 2011 - Extensions of recurrent neural network language model.pdf</url></pdf-urls><web-urls><url>http://ieeexplore.ieee.org/lpdocs/epic03/wrapper.htm?arnumber=5947611</url></web-urls></urls><abstract>We present several modifications of the original recurrent neural net work language model (RNN LM). While this model has been shown to significantly outperform many competitive language modeling techniques in terms of accuracy, the remaining problem is the computational complexity. In this work, we show approaches that lead to more than 15 times speedup for both training and testing phases. Next, we show importance of using a backpropagation through time algorithm. An empirical comparison with feedforward networks is also provided. In the end, we discuss possibilities how to reduce the amount of parameters in the model. The resulting RNN model can thus be smaller, faster both during training and testing, and more accurate than the basic one.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Moreno Velo, Francisco José</author></authors></contributors><titles><title>Tema 3: Fundamentos de la Teoría de Gramáticas Formales</title></titles><periodical/><keywords/><dates><year>2010</year></dates><urls><pdf-urls><url>internal-pdf://Moreno Velo - 2010 - Tema 3 Fundamentos de la Teoría de Gramáticas Formales.pdf</url></pdf-urls><web-urls><url>http://www.uhu.es/francisco.moreno/talf/docs/tema3.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Norvig, Peter</author></authors></contributors><titles><title>Paradigms of Artificial Intelligence Programming: Case Studies in Common Lisp</title></titles><periodical/><pages>946</pages><keywords/><dates><year>2014</year></dates><publisher>Elsevier Science</publisher><isbn>0080571158</isbn><urls><web-urls><url>https://books.google.com/books?id=eH6jBQAAQBAJ&amp;pgis=1</url></web-urls></urls><abstract>Paradigms of AI Programming is the first text to teach advanced Common Lisp techniques in the context of building major AI systems. By reconstructing authentic, complex AI programs using state-of-the-art Common Lisp, the book teaches students and professionals how to build and debug robust practical programs, while demonstrating superior programming style and important AI concepts. The author strongly emphasizes the practical performance issues involved in writing real working programs of significant size. Chapters on troubleshooting and efficiency are included, along with a discussion of the fundamentals of object-oriented programming and a description of the main CLOS functions. This volume is an excellent text for a course on AI programming, a useful supplement for general AI courses and an indispensable reference for the professional programmer.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>OMG</author></authors></contributors><titles><title>Unified Modeling Language (UML)</title></titles><periodical/><pages>1-786</pages><keywords/><dates><year>2015</year></dates><urls><pdf-urls><url>internal-pdf://OMG - 2015 - Unified Modeling Language (UML).pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Pang, Bo</author><author>Lee, Lillian</author></authors></contributors><titles><title>A Sentimental Education: Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts</title><secondary-title>Proceedings of the 42nd Meeting of the Association for Computational Linguistics</secondary-title></titles><periodical><full-title>Proceedings of the 42nd Meeting of the Association for Computational Linguistics</full-title></periodical><pages>271--278</pages><keywords><keyword>analysis</keyword><keyword>sentiment</keyword></keywords><dates><year>2004</year></dates><electronic-resource-num>10.3115/1218955.1218990</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Pang, Lee - 2004 - A Sentimental Education Sentiment Analysis Using Subjectivity Summarization Based on Minimum Cuts.pdf</url></pdf-urls></urls><label>Pang2004</label><abstract>Sentiment analysis seeks to identify the viewpoint(s) underlying a text span; an example application is classifying a movie review as &quot;thumbs up&quot; or &quot;thumbs down&quot;. To determine this sentiment polarity, we propose a novel machine-learning method that applies text-categorization techniques to just the subjective portions of the document. Extracting these portions can be implemented using efficient techniques for finding minimum cuts in graphs; this greatly facilitates incorporation of cross-sentence contextual constraints.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Pang, Bo</author><author>Lee, Lillian</author></authors></contributors><titles><title>Seeing stars: Exploiting class relationships for sentiment categorization with respect to rating scales</title><secondary-title>Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</secondary-title></titles><periodical><full-title>Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics</full-title></periodical><pages>115-124</pages><keywords/><dates><year>2005</year></dates><publisher>Association for Computational Linguistics</publisher><isbn>1932432515</isbn><electronic-resource-num>10.3115/1219840.1219855</electronic-resource-num><notes>http://www.aclweb.org/anthology/P05-1015</notes><research-notes>http://www.aclweb.org/anthology/P05-1015</research-notes><urls><pdf-urls><url>internal-pdf://Pang, Lee - 2005 - Seeing stars Exploiting class relationships for sentiment categorization with respect to rating scales.pdf</url></pdf-urls></urls><label>Pang2005</label><abstract>We address the rating-inference problem, wherein rather than simply decide whether a review is &quot;thumbs up&quot; or &quot;thumbs down&quot;, as in previous sentiment analysis work, one must determine an author's evaluation with respect to a multi-point scale (e.g., one to five &quot;stars&quot;). This task represents an interesting twist on standard multi-class text categorization because there are several different degrees of similarity between class labels; for example, &quot;three stars&quot; is intuitively closer to &quot;four stars&quot; than to &quot;one star&quot;. We first evaluate human performance at the task. Then, we apply a meta-algorithm, based on a metric labeling formulation of the problem, that alters a given n-ary classifier's output in an explicit attempt to ensure that similar items receive similar labels. We show that the meta-algorithm can provide significant improvements over both multi-class and regression versions of SVMs when we employ a novel similarity measure appropriate to the problem.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Pang, Bo</author><author>Lee, Lillian</author><author>Vaithyanathan, Shivakumar</author></authors></contributors><titles><title>Thumbs Up? Sentiment Classification Using Machine Learning Techniques</title><secondary-title>Proceedings of the ACL-02 conference on Empirical Methods in Natural Language Processing</secondary-title></titles><periodical><full-title>Proceedings of the ACL-02 conference on Empirical Methods in Natural Language Processing</full-title></periodical><pages>79-86</pages><volume>10</volume><keywords/><dates><year>2002</year></dates><publisher>Association for Computational Linguistics</publisher><electronic-resource-num>10.3115/1118693.1118704</electronic-resource-num><notes>http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf</notes><research-notes>http://www.cs.cornell.edu/home/llee/papers/sentiment.pdf</research-notes><urls><pdf-urls><url>internal-pdf://Pang, Lee, Vaithyanathan - 2002 - Thumbs Up Sentiment Classification Using Machine Learning Techniques.pdf</url></pdf-urls></urls><label>Pang2002</label><abstract>We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Pedregosa, F.</author><author>Varoquaux, G.</author><author>Gramfort, A.</author><author>Michel, V.</author><author>Thirion, B.</author><author>Grisel, O.</author><author>Blondel, M.</author><author>Prettenhofer, P.</author><author>Weiss, R.</author><author>Dubourg, V.</author><author>Vanderplas, J.</author><author>Passos, A.</author><author>Cournapeau, D.</author><author>Brucher, M.</author><author>Perrot, M.</author><author>Duchesnay, E.</author></authors></contributors><titles><title>Scikit-learn: Machine Learning in Python</title><secondary-title>Journal of Machine Learning Research</secondary-title></titles><periodical><full-title>Journal of Machine Learning Research</full-title></periodical><pages>2825-2830</pages><volume>12</volume><keywords/><dates><year>2011</year></dates><urls><pdf-urls><url>internal-pdf://Pedregosa et al. - 2011 - Scikit-learn Machine Learning in Python.pdf</url></pdf-urls><web-urls><url>http://scikit-learn.org/stable/user_guide.html</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Perkins, Jacob</author></authors></contributors><titles><title>Python Text Processing with NLTK 2.0 Cookbook</title><secondary-title>Python</secondary-title></titles><periodical><full-title>Python</full-title></periodical><pages>544</pages><keywords/><dates><year>2010</year></dates><publisher>Packt Publishing Ltd</publisher><isbn>9781849513609</isbn><urls><pdf-urls><url>internal-pdf://Perkins - 2010 - Python Text Processing with NLTK 2.0 Cookbook.pdf</url></pdf-urls></urls><abstract>Text Processing in Python describes techniques for manipulation of text using the Python programming language. At the broadest level, text processing is simply taking textual information and doing something with it. This might be restructuring or reformatting it, extracting smaller bits of information from it, or performing calculations that depend on the text. Text processing is arguably what most programmers spend most of their time doing. Because Python is clear, expressive, and object-oriented it is a perfect language for doing text processing, even better than Perl. As the amount of data everywhere continues to increase, this is more and more of a challenge for programmers. This book is not a tutorial on Python. It has two other goals: helping the programmer get the job done pragmatically and efficiently; and giving the reader an understanding - both theoretically and conceptually - of why what works and what doesnt work doesnt work. Mertz provides practical pointers and tips that emphasize efficient, flexible, and maintainable approaches to the text processing tasks that working programmers face daily.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Perkins, Jacob</author></authors></contributors><titles><title>Python NLTK Natural Language Processing | StreamHacker</title></titles><periodical/><keywords/><urls><web-urls><url>http://streamhacker.com/</url></web-urls></urls><label>streamhacker</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Perkins, Jacob</author></authors></contributors><titles><title>Python 3 Text Processing with NLTK 3 Cookbook</title></titles><periodical/><keywords/><dates><year>2014</year></dates><publisher>Packt Publishing Ltd</publisher><isbn>978-1-78216-785-3</isbn><urls><pdf-urls><url>internal-pdf://Perkins - 2014 - Python 3 Text Processing with NLTK 3 Cookbook.pdf</url></pdf-urls><web-urls><url>http://it-ebooks.info/book/4469/</url></web-urls></urls><abstract>This book will show you the essential techniques of text and language processing. Starting with tokenization, stemming, and the WordNet dictionary, you'll progress to part-of-speech tagging, phrase chunking, and named entity recognition. You'll learn how various text corpora are organized, as well as how to create your own custom corpus. Then, you'll move onto text classification with a focus on sentiment analysis. And because NLP can be computationally expensive on large bodies of text, you'll try a few methods for distributed text processing. Finally, you'll be introduced to a number of other small but complementary Python libraries for text analysis, cleaning, and parsing.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Porter, Martin F.</author></authors></contributors><titles><title>An algorithm for suffix stripping</title><secondary-title>Program</secondary-title></titles><periodical><full-title>Program</full-title></periodical><pages>130-137</pages><volume>14</volume><issue>3</issue><keywords/><dates><year>1980</year></dates><publisher>MCB UP Ltd</publisher><electronic-resource-num>10.1108/00330330610681286</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Porter - 1980 - An algorithm for suffix stripping.pdf</url><url>internal-pdf://Porter - 1980 - An algorithm for suffix stripping(2).pdf</url></pdf-urls><web-urls><url>http://tartarus.org/martin/PorterStemmer/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Porter, Martin F.</author></authors></contributors><titles><title>An algorithm for suffix stripping</title><secondary-title>Program</secondary-title></titles><periodical><full-title>Program</full-title></periodical><pages>211-218</pages><volume>40</volume><issue>3</issue><keywords/><dates><year>2006</year></dates><electronic-resource-num>10.1108/00330330610681286</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Porter - 1980 - An algorithm for suffix stripping(2).pdf</url></pdf-urls><web-urls><url>http://www.emeraldinsight.com/doi/abs/10.1108/00330330610681286</url></web-urls></urls><abstract>Purpose – The automatic removal of suffixes from words in English is of particular interest in the field of information retrieval. This work was originally published in Program in 1980 and is republished as part of a series of articles commemorating the 40th anniversary of the journal.Design/methodology/approach – An algorithm for suffix stripping is described, which has been implemented as a short, fast program in BCPL.Findings – Although simple, it performs slightly better than a much more elaborate system with which it has been compared. It effectively works by treating complex suffixes as compounds made up of simple suffixes, and removing the simple suffixes in a number of steps. In each step the removal of the suffix is made to depend upon the form of the remaining stem, which usually involves a measure of its syllable length.Originality/value – The piece provides a useful historical document on information retrieval.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Rai, Piyush</author></authors></contributors><titles><title>Data Clustering: K-means and Hierarchical Clustering</title><secondary-title>2011</secondary-title></titles><periodical><full-title>2011</full-title></periodical><keywords/><urls><pdf-urls><url>internal-pdf://Rai - Unknown - Data Clustering K-means and Hierarchical Clustering.pdf</url></pdf-urls><web-urls><url>http://www.cs.utah.edu/~piyush/teaching/4-10-print.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Rehurek, Radim</author></authors></contributors><titles><title>gensim: models.word2vec – Deep learning with word2vec</title></titles><periodical/><keywords/><urls><web-urls><url>http://radimrehurek.com/gensim/models/word2vec.html</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Rehurek, Radim</author></authors></contributors><titles><title>Performance Shootout of Nearest Neighbours: Querying</title></titles><periodical/><keywords><keyword>consulting</keyword><keyword>gensim</keyword><keyword>machine learning</keyword><keyword>programming</keyword><keyword>radim rehurek</keyword></keywords><urls><web-urls><url>http://radimrehurek.com/2014/01/performance-shootout-of-nearest-neighbours-querying/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Rehurek, Radim</author></authors></contributors><titles><title>Word2vec Tutorial</title></titles><periodical/><keywords><keyword>consulting</keyword><keyword>gensim</keyword><keyword>machine learning</keyword><keyword>programming</keyword><keyword>radim rehurek</keyword></keywords><urls><web-urls><url>http://radimrehurek.com/2014/02/word2vec-tutorial/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Rodríguez, María del Mar</author><author>Marauri, Íñigo</author></authors></contributors><titles><title>El control de la reputación on line para prevenir y gestionar una crisis</title><secondary-title>TELOS</secondary-title></titles><periodical><full-title>TELOS</full-title></periodical><pages>98-107</pages><volume>95</volume><issue>Big Data</issue><keywords/><dates><year>2013</year></dates><publisher>Fundación Telefónica Patronato de Fundación Telefónica</publisher><urls><pdf-urls><url>internal-pdf://Rodríguez, Marauri - 2013 - El control de la reputación on line para prevenir y gestionar una crisis.pdf</url></pdf-urls><web-urls><url>http://telos.fundaciontelefonica.com/docs/2013/11/11/11400001_4_4_0.pdf#page=99</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Ruiz Reina, J. L.</author></authors></contributors><titles><title>Aprendizaje de modelos probabilísticos</title></titles><periodical/><keywords/><dates><year>2013</year></dates><publisher>Dpto. Ciencias de la Computación e Inteligencia Artificial. Universidad de Sevilla</publisher><urls><pdf-urls><url>internal-pdf://Ruiz Reina - 2013 - Aprendizaje de modelos probabilísticos.pdf</url></pdf-urls><web-urls><url>http://www.cs.us.es/cursos/ia2/temas/tema-04.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Ruiz, Miguel Ángel</author><author>Pardo, Antonio</author></authors></contributors><titles><title>Análisis discriminante: el procedimiento Discriminante</title></titles><periodical/><keywords/><dates><year>2001</year></dates><urls><pdf-urls><url>internal-pdf://Ruiz, Pardo - 2001 - Análisis discriminante el procedimiento Discriminante.pdf</url></pdf-urls><web-urls><url>http://pendientedemigracion.ucm.es/info/socivmyt/paginas/D_departamento/materiales/analisis_datosyMultivariable/23discr_SPSS.pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Russell, Stuart J.</author><author>Norvig, Peter</author></authors></contributors><titles><title>Artificial Intelligence: A modern approach</title></titles><periodical/><edition>1st</edition><keywords/><dates><year>1995</year></dates><publisher>Prentice-Hall</publisher><urls><pdf-urls><url>internal-pdf://Russell, Norvig - 1995 - Artificial Intelligence A modern approach(2).pdf</url><url>internal-pdf://Russell, Norvig - 1995 - Artificial Intelligence A modern approach.pdf</url></pdf-urls><web-urls><url>http://citeseerx.ist.psu.edu/viewdoc/download?doi=10.1.1.259.8854&amp;rep=rep1&amp;type=pdf</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Russell, Stuart J.</author><author>Norvig, Peter</author></authors></contributors><titles><title>Artificial Intelligence: A Modern Approach</title></titles><periodical/><edition>3rd</edition><keywords/><dates><year>2009</year></dates><pub-location>Upper Saddle River, NJ, USA</pub-location><publisher>Prentice Hall Press</publisher><isbn>0136042597, 9780136042594</isbn><urls><pdf-urls><url>internal-pdf://Russell, Norvig - 2009 - Artificial Intelligence A Modern Approach.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Russell, Stuart J.</author><author>Norvig, Peter</author></authors></contributors><titles><title>Artificial Intelligence: A Modern Approach</title></titles><periodical/><edition>2nd</edition><keywords/><dates><year>2003</year></dates><publisher>Pearson Education</publisher><isbn>0137903952</isbn><urls><pdf-urls><url>internal-pdf://Russell, Norvig - 1996 - Artificial Intelligence A Modern Approach.pdf</url></pdf-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Santorini, Beatrice</author></authors></contributors><titles><title>Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision)</title><secondary-title>Technical Reports (CIS)</secondary-title></titles><periodical><full-title>Technical Reports (CIS)</full-title></periodical><pages>Paper 570</pages><keywords/><dates><year>1990</year></dates><urls><pdf-urls><url>internal-pdf://Santorini - 1990 - Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision).ps</url><url>internal-pdf://Santorini - 1990 - Part-of-Speech Tagging Guidelines for the Penn Treebank Project (3rd Revision).pdf</url></pdf-urls></urls><abstract>This manual addresses the linguistic issues that arise in connection with annotating texts by part of speech (&quot;tagging&quot;). Section 2 is an alphabetical list of the parts of speech encoded in the annotation systems of the Penn Treebank Project, along with their corresponding abbreviations (&quot;tags&quot;) and some information concerning their definition. This section allows you to find an unfamiliar tag by looking up a familiar part of speech. Section 3 recapitulates the information in Section 2, but this time the information is alphabetically ordered by tags. This is the section to consult in order to find out what an unfamiliar tag means. Since the parts of speech are probably familiar to you from high school English, you should have little difficulty in assimilating the tags themselves. However, it is often quite difficult to decide which tag is appropriate in a particular context. The two sections 4 and 5 therefore include examples and guidelines on how to tag problematic cases. If you are uncertain about whether a given tag is correct or not, refer to these sections in order to ensure a consistently annotated text. Section 4 discusses parts of speech that are easily confused and gives guidelines on how to tag such cases, while Section 5 contains an alphabetical list of specific problematic words and collocations. Finally, Section 6 discusses some general tagging conventions. One general rule, however, is so important that we state it here. Many texts are not models of good prose, and some contain outright errors and slips of the pen. Do not be tempted to correct a tag to what it would be if the text were correct; rather, it is the incorrect word that should be tagged correctly.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Thesis">2</ref-type><contributors><authors><author>Socher, Richard</author></authors></contributors><titles><title>Recursive Deep Learning for Natural Language Processing and Computer Vision</title></titles><periodical/><keywords/><dates><year>2014</year></dates><publisher>Stanford University</publisher><urls><pdf-urls><url>internal-pdf://Socher - 2014 - Recursive Deep Learning for Natural Language Processing and Computer Vision.pdf</url></pdf-urls><web-urls><url>http://nlp.stanford.edu/~socherr/thesis.pdf</url></web-urls></urls><label>Socher2014</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Socher, Richard</author><author>Huval, Brody</author><author>Manning, Christopher D.</author><author>Ng, Andrew Y.</author></authors></contributors><titles><title>Semantic compositionality through recursive matrix-vector spaces</title><secondary-title>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</secondary-title></titles><periodical><full-title>Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</full-title></periodical><pages>1201-1211</pages><keywords/><dates><year>2012</year></dates><pub-location>Stroudsburg, PA, USA</pub-location><publisher>Association for Computational Linguistics</publisher><isbn>9781937284435</isbn><urls><pdf-urls><url>internal-pdf://Socher et al. - 2012 - Semantic compositionality through recursive matrix-vector spaces.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=2391084</url></web-urls></urls><label>Socher2012</label><abstract>Single-word vector space models have been very successful at learning lexical informa- tion. However, they cannot capture the com- positional meaning of longer phrases, prevent- ing them from a deeper understanding of lan- guage. We introduce a recursive neural net- work (RNN) model that learns compositional vector representations for phrases and sen- tences of arbitrary syntactic type and length. Our model assigns a vector and a matrix to ev- ery node in a parse tree: the vector captures the inherent meaning of the constituent, while the matrix captures how it changes the mean- ing of neighboring words or phrases. This matrix-vector RNN can learn the meaning of operators in propositional logic and natural language. The model obtains state of the art performance on three different experiments: predicting fine-grained sentiment distributions of adverb-adjective pairs; classifying senti- ment labels of movie reviews and classifying semantic relationships such as cause-effect or topic-message between nouns using the syn- tactic path between them.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Socher, Richard</author><author>Lin, Cliff Chiung-yu C.C.-Y.</author><author>Ng, Andrew Y.</author><author>Manning, Christopher D.</author></authors></contributors><titles><title>Parsing natural scenes and natural language with recursive neural networks</title><secondary-title>Proceedings of the 28th International Conference on Machine Learning</secondary-title></titles><periodical><full-title>Proceedings of the 28th International Conference on Machine Learning</full-title></periodical><pages>129-136</pages><keywords/><dates><year>2011</year></dates><pub-location>Computer Science Department, Stanford University</pub-location><urls><pdf-urls><url>internal-pdf://Socher et al. - 2011 - Parsing natural scenes and natural language with recursive neural networks.pdf</url></pdf-urls><web-urls><url>http://fur.ly/0/Socher2011</url></web-urls></urls><label>Socher2011a</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Socher, Richard</author><author>Pennington, Jeffrey</author><author>Huang, Eric H.</author><author>Ng, Andrew Y.</author><author>Manning, Christopher D.</author></authors></contributors><titles><title>Semi-supervised Recursive Autoencoders for Predicting Sentiment Distributions</title><secondary-title>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</secondary-title></titles><periodical><full-title>Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing</full-title></periodical><pages>151-161</pages><keywords/><dates><year>2011</year></dates><pub-location>Stroudsburg, PA, USA</pub-location><publisher>Association for Computational Linguistics</publisher><isbn>978-1-937284-11-4</isbn><notes>http://www.aclweb.org/anthology/D11-1014</notes><research-notes>http://www.aclweb.org/anthology/D11-1014</research-notes><urls><pdf-urls><url>internal-pdf://Socher et al. - 2011 - Semi-supervised Recursive Autoencoders for Predicting Sentiment Distributions.pdf</url></pdf-urls><web-urls><url>http://dl.acm.org/citation.cfm?id=2145450</url></web-urls></urls><label>Socher2011b</label><abstract>We introduce a novel machine learning framework based on recursive autoencoders for sentence-level prediction of sentiment label distributions. Our method learns vector space representations for multi-word phrases. In sentiment prediction tasks these representations outperform other state-of-the-art approaches on commonly used datasets, such as movie reviews, without using any pre-defined sentiment lexica or polarity shifting rules. We also evaluate the model's ability to predict sentiment distributions on a new dataset based on confessions from the experience project. The dataset consists of personal user stories annotated with multiple labels which, when aggregated, form a multinomial distribution that captures emotional reactions. Our algorithm can more accurately predict distributions over such labels compared to several competitive baselines.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Socher, Richard</author><author>Perelygin, Alex</author><author>Wu, Jean Y.</author><author>Chuang, Jason</author><author>Manning, Christopher D.</author><author>Ng, Andrew Y.</author><author>Potts, Christopher</author></authors></contributors><titles><title>Recursive deep models for semantic compositionality over a sentiment treebank</title><secondary-title>Proceedings of the 2013 conference on Empirical Methods in Natural Language Processing</secondary-title></titles><periodical><full-title>Proceedings of the 2013 conference on Empirical Methods in Natural Language Processing</full-title></periodical><pages>1631-1642</pages><keywords/><dates><year>2013</year></dates><publisher>Association for Computational Linguistics</publisher><urls><pdf-urls><url>internal-pdf://Socher et al. - 2013 - Recursive deep models for semantic compositionality over a sentiment treebank.pdf</url></pdf-urls><web-urls><url>http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf</url></web-urls></urls><abstract>Semantic word spaces have been very useful but cannot express the meaning of longer phrases in a principled way. Further progress towards understanding compositionality in tasks such as sentiment detection requires richer supervised training and evaluation resources and more powerful models of composition. To remedy this, we introduce a Sentiment Treebank. It includes fine grained sentiment labels for 215,154 phrases in the parse trees of 11,855 sentences and presents new challenges for sentiment compositionality. To address them, we introduce the Recursive Neural Tensor Network. When trained on the new treebank, this model outperforms all previous methods on several metrics. It pushes the state of the art in single sentence positive/negative classification from 80% up to 85.4%. The accuracy of predicting fine-grained sentiment labels for all phrases reaches 80.7%, an improvement of 9.7% over bag of features baselines. Lastly, it is the only model that can accurately capture the effects of negation and its scope at various tree levels for both positive and negative phrases.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Summerfield, Mark</author></authors></contributors><titles><title>Rapid GUI programming with Python and Qt: the definitive guide to PyQt programming</title></titles><periodical/><keywords><keyword>Användargränssnitt</keyword><keyword>Python (programspråk)</keyword><keyword>Qt (Electronic resource)</keyword></keywords><dates><year>2008</year></dates><publisher>Prentice Hall</publisher><isbn>9780132354189</isbn><urls><pdf-urls><url>internal-pdf://Summerfield - 2008 - Rapid GUI programming with Python and Qt the definitive guide to PyQt programming.pdf</url></pdf-urls><web-urls><url>http://fp5qq3tk5q.search.serialssolutions.com?ctx_ver=Z39.88-2004&amp;ctx_enc=info:ofi/enc:UTF-8&amp;rfr_id=info:sid/summon.serialssolutions.com&amp;rft_val_fmt=info:ofi/fmt:kev:mtx:book&amp;rft.genre=book&amp;rft.title=Rapid+GUI+programming+with+Python+and+Qt&amp;rft.au=S</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>The Shogun Toolbox Foundation</author></authors></contributors><titles><title>Machine Learning toolboxes feature comparision matrix</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><pdf-urls><url>internal-pdf://The Shogun Toolbox Foundation - 2015 - Machine Learning toolboxes feature comparision matrix.pdf</url></pdf-urls><web-urls><url>http://www.shogun-toolbox.org/page/features/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>The Stanford Natural Language Processing Group</author></authors></contributors><titles><title>The Stanford Parser: A statistical parser</title></titles><periodical/><keywords/><urls><web-urls><url>http://nlp.stanford.edu/software/lex-parser.shtml</url></web-urls></urls><label>standforparser</label></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Conference Proceedings">3</ref-type><contributors><authors><author>Turian, Joseph</author><author>Ratinov, Lev</author><author>Bengio, Yoshua</author></authors></contributors><titles><title>Word Representations: A Simple and General Method for Semi-supervised Learning</title><secondary-title>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</secondary-title></titles><periodical><full-title>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics</full-title></periodical><pages>384-394</pages><keywords/><dates><year>2010</year></dates><isbn>9781617388088</isbn><urls><pdf-urls><url>internal-pdf://Turian, Ratinov, Bengio - 2010 - Word Representations A Simple and General Method for Semi-supervised Learning.pdf</url></pdf-urls><web-urls><url>http://www.iro.umontreal.ca/~lisa/pointeurs/turian-wordrepresentations-acl10.pdf</url></web-urls></urls><label>Turian2010</label><abstract>If we take an existing supervised NLP system, a simple and general way to improve accuracy is to use unsupervised word representations as extra word features. We evaluate Brown clusters, Collobert and Weston (2008) embeddings, and HLBL (Mnih &amp; Hinton, 2009) embeddings of words on both NER and chunking. We use near state-of-the-art supervised baselines, and find that each of the three word representations improves the accuracy of these baselines. We find further improvements by combining different word representations. You can download our word features, for off-the-shelf use in existing NLP systems, as well as our code, here: http://metaoptimize.com/projects/wordreprs/</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Turney, Peter D.</author><author>Pantel, Patrick</author></authors></contributors><titles><title>From frequency to meaning: Vector space models of semantics</title><secondary-title>Journal of Artificial Intelligence Research</secondary-title></titles><periodical><full-title>Journal of Artificial Intelligence Research</full-title></periodical><pages>141-188</pages><volume>37</volume><keywords><keyword>ALGORITHM</keyword><keyword>CATEGORIZATION</keyword><keyword>COMMUNICATION</keyword><keyword>COOCCURRENCE</keyword><keyword>DECOMPOSITION</keyword><keyword>INFORMATION</keyword><keyword>MATHEMATICAL-THEORY</keyword><keyword>RETRIEVAL</keyword><keyword>SIMILARITY</keyword><keyword>TEXT</keyword></keywords><dates><year>2010</year></dates><pub-location>USC INFORMATION SCIENCES INST, 4676 ADMIRALITY WAY, MARINA DEL REY, CA 90292-6695 USA</pub-location><publisher>AI ACCESS FOUNDATION</publisher><urls><pdf-urls><url>internal-pdf://Turney, Pantel - 2010 - From frequency to meaning Vector space models of semantics.pdf</url></pdf-urls></urls><abstract>Computers understand very little of the meaning of human language. This profoundly limits our ability to give instructions to computers, the ability of computers to explain their actions to us, and the ability of computers to analyse and process text. Vector space models (VSMs) of semantics are beginning to address these limits. This paper surveys the use of VSMs for semantic processing of text. We organize the literature on VSMs according to the structure of the matrix in a VSM. There are currently three broad classes of VSMs, based on term-document, word-context, and pair-pattern matrices, yielding three classes of applications. We survey a broad range of applications in these three categories and we take a detailed look at a specific open source project in each category. Our goal in this survey is to show the breadth of applications of VSMs for semantics, to provide a new perspective on VSMs for those who are already familiar with the area, and to provide pointers into the literature for those who are less familiar with the field.</abstract></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Van Rijsbergen, Cornelis J.</author><author>Robertson, Stephen Edward</author><author>Porter, Martin F.</author></authors></contributors><titles><title>New models in probabilistic information retrieval</title></titles><periodical/><keywords/><dates><year>1980</year></dates><publisher>Computer Laboratory, University of Cambridge</publisher><urls><web-urls><url>http://www.sigir.org/files/museum/pub-21/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Wikipedia</author></authors></contributors><titles><title>Curse of dimensionality</title></titles><periodical/><keywords/><dates><year>2014</year></dates><urls><web-urls><url>http://en.wikipedia.org/wiki/Curse_of_dimensionality</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Wikipedia</author></authors></contributors><titles><title>Wikipedia en Español</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><web-urls><url>http://es.wikipedia.org/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Web Page">16</ref-type><contributors><authors><author>Wikipedia</author></authors></contributors><titles><title>Wikipedia in English</title></titles><periodical/><keywords/><dates><year>2015</year></dates><urls><web-urls><url>http://en.wikipedia.org/</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Book">1</ref-type><contributors><authors><author>Zecchetto, Victorino</author></authors></contributors><titles><title>La danza de los signos: nociones de semiótica general</title></titles><periodical/><keywords/><dates><year>2003</year></dates><publisher>La Cruj{í}a</publisher><isbn>9789871004195</isbn><urls><pdf-urls><url>internal-pdf://Zecchetto - 2003 - La danza de los signos nociones de semiótica general.pdf</url></pdf-urls><web-urls><url>https://books.google.es/books?id=sbHjAAAAMAAJ</url></web-urls></urls></record><record><database name="mendeley.enl" path="mendeley.enl">mendeley.enl</database><ref-type name="Journal Article">0</ref-type><contributors><authors><author>Zhang, Dongwen</author><author>Xu, Hua</author><author>Su, Zengcai</author><author>Xu, Yunfeng</author></authors></contributors><titles><title>Chinese comments sentiment classification based on word2vec and SVMperf</title><secondary-title>Expert Systems with Applications</secondary-title></titles><periodical><full-title>Expert Systems with Applications</full-title></periodical><pages>1857-1863</pages><volume>42</volume><issue>4</issue><keywords><keyword>Semantic features</keyword><keyword>Sentiment classification</keyword><keyword>Word2vec</keyword><keyword>{SVMperf}</keyword></keywords><dates><year>2015</year></dates><electronic-resource-num>10.1016/j.eswa.2014.09.011</electronic-resource-num><urls><pdf-urls><url>internal-pdf://Zhang et al. - 2015 - Chinese comments sentiment classification based on word2vec and SVMperf.pdf</url></pdf-urls><web-urls><url>http://www.sciencedirect.com/science/article/pii/S0957417414005508</url></web-urls></urls><abstract>Since the booming development of e-commerce in the last decade, the researchers have begun to pay more attention to extract the valuable information from consumers comments. Sentiment classification, which focuses on classify the comments into positive class and negative class according to the polarity of sentiment, is one of the studies. Machine learning-based method for sentiment classification becomes mainstream due to its outstanding performance. Most of the existing researches are centered on the extraction of lexical features and syntactic features, while the semantic relationships between words are ignored. In this paper, in order to get the semantic features, we propose a method for sentiment classification based on word2vec and SVMperf. Our research consists of two parts of work. First of all, we use word2vec to cluster the similar features for purpose of showing the capability of word2vec to capture the semantic features in selected domain and Chinese language. And then, we train and classify the comment texts using word2vec again and SVMperf. In the process, the lexicon-based and part-of-speech-based feature selection methods are respectively adopted to generate the training file. We conduct the experiments on the data set of Chinese comments on clothing products. The experimental results show the superior performance of our method in sentiment classification.</abstract></record></records></xml>
