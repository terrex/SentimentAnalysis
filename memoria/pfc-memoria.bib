
@Book{            bird2009,
  abstract      = {This book offers a highly accessible introduction to
                  natural language processing, the field that supports a
                  variety of language technologies, from predictive text and
                  email filtering to automatic summarization and translation.
                  With it, you'll learn how to write Python programs that
                  work with large collections of unstructured text. You'll
                  access richly annotated datasets using a comprehensive
                  range of linguistic data structures, and you'll understand
                  the main algorithms for analyzing the content and structure
                  of written communication. Packed with examples and
                  exercises, Natural Language Processing with Python will
                  help you:Extract information from unstructured text, either
                  to guess the topic or identify "named entities" Analyze
                  linguistic structure in text, including parsing and
                  semantic analysis Access popular linguistic databases,
                  including WordNet and treebanks Integrate techniques drawn
                  from fields as diverse as linguistics and artificial
                  intelligence This book will help you gain practical skills
                  in natural language processing using the Python programming
                  language and the Natural Language Toolkit (NLTK) open
                  source library. If you're interested in developing web
                  applications, analyzing multilingual news sources, or
                  documenting endangered languages - or if you're simply
                  curious to have a programmer's perspective on how human
                  language works - you'll find Natural Language Processing
                  with Python both fascinating and immensely useful.},
  author        = {Steven Bird and Ewan Klein and Edward Loper},
  booktitle     = {Text},
  isbn          = {9780596516499},
  issn          = {00992399},
  pages         = {479},
  pmid          = {12043876},
  title         = {{Natural Language Processing with Python}},
  url           = {http://www.nltk.org/book/},
  urldate       = {2014-11-09},
  volume        = {43},
  year          = {2009},
  url           = {http://www.nltk.org/book/}
}

@PhDThesis{       bobrow1964,
  abstract      = {This paper describes a computer program which accepts and
                  «understands» a comfortable, but restricted set of one
                  natural language, English. Certain difficulties are
                  inherent in this problem of making a machine «understand»
                  English. Within the limited framework of the subject matter
                  understood by the program, many of these problems are
                  solved or circumvented. I shall describe these problems and
                  my solutions, and point out those solutions which I feel
                  have general applicability. I will also indicate which must
                  be replaced by more general methods to be really useful,
                  and give my ideas about what general solutions to these
                  particular problems might entail.},
  author        = {Daniel G. Bobrow},
  month         = {March},
  school        = {MIT},
  title         = {Natural Language Input for a Computer Problem Solving
                  System},
  url           = {http://hdl.handle.net/1721.1/5922},
  urldate       = {2014-11-09},
  year          = {1964},
  url           = {http://hdl.handle.net/1721.1/5922}
}

@Article{         domingos2012,
  abstract      = {MACHINE LEARNING SYSTEMS automatically learn programs from
                  data. This is often a very attractive alternative to
                  manually constructing them, and in the last decade the use
                  of machine learning has spread rapidly throughout computer
                  science and beyond. Machine learning is used in Web search,
                  spam filters, recommender systems, ad placement, credit
                  scoring, fraud detection, stock trading, drug design, and
                  many other applications. A recent report from the McKinsey
                  Global Institute asserts that machine learning (a.k.a. data
                  mining or predictive analytics) will be the driver of the
                  next big wave of innovation. Several fine textbooks are
                  available to interested practitioners and researchers (for
                  example, Mitchell and Witten et al.). However, much of the
                  ``folk knowledge'' that is needed to successfully develop
                  machine learning applications is not readily available in
                  them. As a result, many machine learning projects take much
                  longer than necessary or wind up producing less-than-ideal
                  results. Yet much of this folk knowledge is fairly easy to
                  communicate. This is the purpose of this article.},
  author        = {Domingos, Pedro},
  doi           = {10.1145/2347736.2347755},
  isbn          = {0001-0782},
  issn          = {00010782},
  journal       = {Communications of the ACM},
  month         = oct,
  number        = {10},
  pages         = {78},
  title         = {{A few useful things to know about machine learning}},
  url           = {http://dl.acm.org/citation.cfm?doid=2347736.2347755},
  urldate       = {2014-11-09},
  volume        = {55},
  year          = {2012},
  url           = {http://dl.acm.org/citation.cfm?doid=2347736.2347755}
}

@Electronic{      gabilondo2011,
  author        = {Michael Gabilondo},
  title         = {How to perform some common NLP tasks using NLTK},
  url           = {http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf},
  urldate       = {2014-11-22},
  url           = {http://www.cs.ucf.edu/courses/cap5636/fall2011/nltk.pdf}
}

@InProceedings{   gabrilovich2005,
  abstract      = {We enhance machine learning algorithms for text
                  categorization with generated features based on
                  domain-specific and common-sense knowledge. This knowledge
                  is represented using publicly available ontologies that
                  contain hundreds of thousands of concepts, such as the Open
                  Directory; these ontologies are further enriched by several
                  orders of magnitude through controlled Web crawling. Prior
                  to text categorization, a feature generator analyzes the
                  documents and maps them onto appropriate ontology concepts,
                  which in turn induce a set of generated features that
                  augment the standard bag of words. Feature generation is
                  accomplished through contextual analysis of document text,
                  implicitly performing word sense disambiguation. Coupled
                  with the ability to generalize concepts using the ontology,
                  this approach addresses the two main problems of natural
                  language processing---synonymy and polysemy. Categorizing
                  documents with the aid of knowledge-based features
                  leverages information that cannot be deduced from the
                  documents alone. Experimental results confirm improved
                  performance, breaking through the plateau previously
                  reached in the field.},
  author        = {Gabrilovich, Evgeniy and Markovitch, Shaul},
  booktitle     = {Proceedings of the Nineteenth International Joint
                  Conference for Artificial Intelligence},
  pages         = {1048--1053},
  title         = {{Feature Generation for Text Categorization Using World
                  Knowledge}},
  url           = {http://www.cs.technion.ac.il/~shaulm/papers/pdf/Gabrilovich-Markovitch-ijcai2005.pdf}
                  ,
  urldate       = {2014-11-09},
  year          = {2005},
  url           = {http://www.cs.technion.ac.il/~shaulm/papers/pdf/Gabrilovich-Markovitch-ijcai2005.pdf}
                  
}

@Electronic{      kivy,
  author        = {{kivy.org}},
  title         = {Kivy Documentation. Release 1.9.0-dev},
  url           = {http://kivy.org/docs/pdf/Kivy-latest.pdf},
  urldate       = {2014-09-24},
  url           = {http://kivy.org/docs/pdf/Kivy-latest.pdf}
}

@Book{            manning2008,
  abstract      = {Introduction to Information Retrieval is the first
                  textbook with a coherent treatment of classical and web
                  information retrieval, including web search and the related
                  areas of text classification and text clustering. Written
                  from a computer science perspective, it gives an up-to-date
                  treatment of all aspects of the design and implementation
                  of systems for gathering, indexing, and searching
                  documents; methods for evaluating systems; and an
                  introduction to the use of machine learning methods on text
                  collections. Designed as the primary text for a graduate or
                  advanced undergraduate course in information retrieval, the
                  book will also interest researchers and professionals. A
                  complete set of lecture slides and exercises that accompany
                  the book are available on the web.},
  author        = {Manning, Christopher D and Raghavan, Prabhakar and
                  Sch\"{u}tze, Hinrich},
  booktitle     = {Journal of the American Society for Information Science
                  and Technology},
  doi           = {10.1002/asi.21234},
  isbn          = {0521865719},
  issn          = {15322890},
  pages         = {496},
  pmid          = {12049181},
  title         = {{Introduction to Information Retrieval}},
  url           = {http://nlp.stanford.edu/IR-book/information-retrieval-book.html}
                  ,
  urldate       = {2014-11-09},
  volume        = {1},
  year          = {2008},
  url           = {http://nlp.stanford.edu/IR-book/information-retrieval-book.html}
                  
}

@InProceedings{   pang2002,
  abstract      = {We consider the problem of classifying documents not by
                  topic, but by overall sentiment, e.g., determining whether
                  a review is positive or negative. Using movie reviews as
                  data, we find that standard machine learning techniques
                  definitively outperform human-produced baselines. However,
                  the three machine learning methods we employed (Naive
                  Bayes, maximum entropy classification, and support vector
                  machines) do not perform as well on sentiment
                  classification as on traditional topic-based
                  categorization. We conclude by examining factors that make
                  the sentiment classification problem more challenging.},
  author        = {Bo Pang and Lillian Lee and Shivakumar Vaithyanathan},
  booktitle     = {Proceedings of EMNLP},
  pages         = {79--86},
  title         = {Thumbs Up? Sentiment Classification Using Machine Learning
                  Techniques},
  url           = {http://dl.acm.org/citation.cfm?id=1118704},
  urldate       = {2014-09-29},
  year          = {2002},
  url           = {http://dl.acm.org/citation.cfm?id=1118704}
}

@InProceedings{   pang2004,
  abstract      = {Sentiment analysis seeks to identify the viewpoint(s)
                  underlying a text span; an example application is
                  classifying a movie review as ``thumbs up'' or ``thumbs
                  down''. To determine this sentiment polarity, we propose a
                  novel machine-learning method that applies
                  text-categorization techniques to just the subjective
                  portions of the document. Extracting these portions can be
                  implemented using efficient techniques for finding minimum
                  cuts in graphs; this greatly facilitates incorporation of
                  cross-sentence contextual constraints.},
  author        = {Bo Pang and Lillian Lee},
  booktitle     = {Proceedings of ACL},
  pages         = {271--278},
  title         = {A Sentimental Education: Sentiment Analysis Using
                  Subjectivity Summarization Based on Minimum Cuts},
  url           = {http://dl.acm.org/citation.cfm?id=1218990},
  urldate       = {2014-09-29},
  year          = {2004},
  url           = {http://dl.acm.org/citation.cfm?id=1218990}
}

@InProceedings{   pang2005,
  abstract      = {We address the rating-inference problem, wherein rather
                  than simply decide whether a review is ``thumbs up'' or
                  ``thumbs down'', as in previous sentiment analysis work,
                  one must determine an author's evaluation with respect to a
                  multi-point scale (e.g., one to five ``stars''). This task
                  represents an interesting twist on standard multi-class
                  text categorization because there are several different
                  degrees of similarity between class labels; for example,
                  ``three stars'' is intuitively closer to ``four stars''
                  than to ``one star''.
                  
                  We first evaluate human performance at the task. Then, we
                  apply a meta-algorithm, based on a metric labeling
                  formulation of the problem, that alters a given n-ary
                  classifier's output in an explicit attempt to ensure that
                  similar items receive similar labels. We show that the
                  meta-algorithm can provide significant improvements over
                  both multi-class and regression versions of SVMs when we
                  employ a novel similarity measure appropriate to the
                  problem.},
  author        = {Bo Pang and Lillian Lee},
  booktitle     = {Proceedings of ACL},
  pages         = {115--124},
  title         = {Seeing Stars: Exploiting Class Relationships For Sentiment
                  Categorization With Respect To Rating Scales},
  url           = {http://dl.acm.org/citation.cfm?id=1219855},
  urldate       = {2014-09-29},
  year          = {2005},
  url           = {http://dl.acm.org/citation.cfm?id=1219855}
}

@Book{            perkins2003,
  abstract      = {Text Processing in Python describes techniques for
                  manipulation of text using the Python programming language.
                  At the broadest level, text processing is simply taking
                  textual information and doing something with it. This might
                  be restructuring or reformatting it, extracting smaller
                  bits of information from it, or performing calculations
                  that depend on the text. Text processing is arguably what
                  most programmers spend most of their time doing. Because
                  Python is clear, expressive, and object-oriented it is a
                  perfect language for doing text processing, even better
                  than Perl. As the amount of data everywhere continues to
                  increase, this is more and more of a challenge for
                  programmers. This book is not a tutorial on Python. It has
                  two other goals: helping the programmer get the job done
                  pragmatically and efficiently; and giving the reader an
                  understanding - both theoretically and conceptually - of
                  why what works and what doesnt work doesnt work. Mertz
                  provides practical pointers and tips that emphasize
                  efficient, flexible, and maintainable approaches to the
                  text processing tasks that working programmers face
                  daily.},
  author        = {Jacob Perkins},
  booktitle     = {Python},
  isbn          = {9781849513609},
  pages         = {544},
  publisher     = {Packt Publishing},
  title         = {Python Text Processing with NLTK 2.0 Cookbook},
  year          = {2003}
}

@InProceedings{   socher2011a,
  address       = {Computer Science Department, Stanford University},
  author        = {Socher, R. and Lin, C.C.-Y. and Ng, A.Y. and Manning,
                  C.D.},
  booktitle     = {Proceedings of the 28th International Conference on
                  Machine Learning, ICML 2011},
  pages         = {129-136},
  title         = {Parsing natural scenes and natural language with recursive
                  neural networks.},
  url           = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Socher_125.pdf}
                  ,
  urldate       = {2014-09-29},
  year          = {2011},
  url           = {http://machinelearning.wustl.edu/mlpapers/paper_files/ICML2011Socher_125.pdf}
                  
}

@InProceedings{   socher2011b,
  acmid         = {2145450},
  address       = {Stroudsburg, PA, USA},
  author        = {Socher, Richard and Pennington, Jeffrey and Huang, Eric H.
                  and Ng, Andrew Y. and Manning, Christopher D.},
  booktitle     = {Proceedings of the Conference on Empirical Methods in
                  Natural Language Processing},
  isbn          = {978-1-937284-11-4},
  location      = {Edinburgh, United Kingdom},
  numpages      = {11},
  pages         = {151--161},
  publisher     = {Association for Computational Linguistics},
  series        = {EMNLP '11},
  title         = {Semi-supervised Recursive Autoencoders for Predicting
                  Sentiment Distributions},
  url           = {http://dl.acm.org/citation.cfm?id=2145450},
  year          = {2011},
  url           = {http://dl.acm.org/citation.cfm?id=2145450}
}

@InProceedings{   socher2012,
  acmid         = {2391084},
  address       = {Stroudsburg, PA, USA},
  author        = {Socher, Richard and Huval, Brody and Manning, Christopher
                  D. and Ng, Andrew Y.},
  booktitle     = {Proceedings of the 2012 Joint Conference on Empirical
                  Methods in Natural Language Processing and Computational
                  Natural Language Learning},
  location      = {Jeju Island, Korea},
  numpages      = {11},
  pages         = {1201--1211},
  publisher     = {Association for Computational Linguistics},
  series        = {EMNLP-CoNLL '12},
  title         = {Semantic Compositionality Through Recursive Matrix-vector
                  Spaces},
  url           = {http://dl.acm.org/citation.cfm?id=2391084},
  year          = {2012},
  url           = {http://dl.acm.org/citation.cfm?id=2391084}
}

@Article{         socher2013,
  abstract      = {Semantic word spaces have been very useful but cannot
                  express the meaning of longer phrases in a principled way.
                  Further progress towards understanding compositionality in
                  tasks such as sentiment detection requires richer
                  supervised training and evaluation resources and more
                  powerful models of composition. To remedy this, we
                  introduce a Sentiment Treebank. It includes fine grained
                  sentiment labels for 215,154 phrases in the parse trees of
                  11,855 sentences and presents new challenges for sentiment
                  compositionality. To address them, we introduce the
                  Recursive Neural Tensor Network. When trained on the new
                  treebank, this model outperforms all previous methods on
                  several metrics. It pushes the state of the art in single
                  sentence positive/negative classification from 80\% up to
                  85.4\%. The accuracy of predicting fine-grained sentiment
                  labels for all phrases reaches 80.7\%, an improvement of
                  9.7\% over bag of features baselines. Lastly, it is the
                  only model that can accurately capture the effects of
                  negation and its scope at various tree levels for both
                  positive and negative phrases.},
  author        = {Richard Socher and Alex Perelygin and Jean Y. Wu and Jason
                  Chuang and Christopher D. Manning and Andrew Y. Ng and
                  Christopher Potts},
  journal       = {Proceedings of the \ldots},
  pages         = {1631--1642},
  title         = {Recursive Deep Models for Semantic Compositionality Over a
                  Sentiment Treebank},
  url           = {http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf},
  urldate       = {2014-11-09},
  year          = {2013},
  url           = {http://nlp.stanford.edu/~socherr/EMNLP2013_RNTN.pdf}
}

@Electronic{      standforparser,
  author        = {{The Stanford Natural Language Processing Group}},
  title         = {The Stanford Parser: A statistical parser},
  url           = {http://nlp.stanford.edu/software/lex-parser.shtml},
  urldate       = {2014-11-09},
  url           = {http://nlp.stanford.edu/software/lex-parser.shtml}
}

@Electronic{      streamhacker,
  author        = {Jacob Perkins},
  title         = {Python NLTK Natural Language Processing | StreamHacker},
  url           = {http://streamhacker.com/},
  urldate       = {2014-11-09},
  url           = {http://streamhacker.com/}
}

@Electronic{      wikipedia:bigdata,
  author        = {Wikipedia},
  title         = {Big data},
  url           = {http://en.wikipedia.org/wiki/Big_data},
  urldate       = {2014-11-09},
  url           = {http://en.wikipedia.org/wiki/Big_data}
}

@Electronic{      wikipedia:curse-dimens,
  author        = {Wikipedia},
  title         = {Curse of dimensionality},
  url           = {http://en.wikipedia.org/wiki/Curse_of_dimensionality},
  urldate       = {2014-09-21},
  url           = {http://en.wikipedia.org/wiki/Curse_of_dimensionality}
}

@Electronic{      wikipedia:knn,
  author        = {Wikipedia},
  title         = {k-nearest neighbors algorithm},
  url           = {http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm}
                  ,
  urldate       = {2014-09-21},
  url           = {http://en.wikipedia.org/wiki/K-nearest_neighbors_algorithm}
                  
}

@Electronic{      wikipedia:svm,
  author        = {Wikipedia},
  title         = {Support Vector Machine},
  url           = {http://en.wikipedia.org/wiki/Support_vector_machine},
  urldate       = {2014-09-11},
  url           = {http://en.wikipedia.org/wiki/Support_vector_machine}
}
